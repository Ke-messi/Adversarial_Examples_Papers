# A compelete list of papers about adversarial examples

It appears that the [List of All Adversarial Example Papers](https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html) has been experiencing crashes over the past few days. In the absence of this valuable resource, staying up-to-date with the latest research papers in this field has become challenging. Consequently, I created a repository aimed at aggregating and maintaining the most current papers in this domain. While this repository may not encompass every paper, I did try. If you find any papers we have missed, just drop me an [email](mailto:xswanghuster@gmail.com). We have included the [data](./nicholas.md) from [List of All Adversarial Example Papers](https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html) till 2023-09-01.
## 2023-09-27
+ [ Bias Assessment and Mitigation in LLM-based Code Generation](https://arxiv.org//abs/2309.14345)`uncheck`

	Dong Huang, Qingwen Bu, Jie Zhang, Xiaofei Xie, Junjie Chen, Heming Cui


+ [ Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM](https://arxiv.org//abs/2309.14348)`uncheck`

	Bochuan Cao, Yuanpu Cao, Lu Lin, Jinghui Chen


+ [ Survey of Social Bias in Vision-Language Models](https://arxiv.org//abs/2309.14381)`uncheck`

	Nayeon Lee, Yejin Bang, Holy Lovenia, Samuel Cahyawijaya, Wenliang Dai, Pascale Fung


+ [ XGV-BERT: Leveraging Contextualized Language Model and Graph Neural  Network for Efficient Software Vulnerability Detection](https://arxiv.org//abs/2309.14677)`uncheck`

	Vu Le Anh Quan, Chau Thuan Phat, Kiet Van Nguyen, Phan The Duy, Van-Hau Pham


+ [ DifAttack: Query-Efficient Black-Box Attack via Disentangled Feature  Space](https://arxiv.org//abs/2309.14585)`uncheck`

	Liu Jun, Zhou Jiantao, Zeng Jiandian, Jinyu Tian


+ [ Structure Invariant Transformation for better Adversarial  Transferability](https://arxiv.org//abs/2309.14700)`uncheck`

	Xiaosen Wang, Zeliang Zhang, Jianping Zhang


+ [ Frugal Satellite Image Change Detection with Deep-Net Inversion](https://arxiv.org//abs/2309.14781)`uncheck`

	Hichem Sahbi, Sebastien Deschamps


+ [ The Surveillance AI Pipeline](https://arxiv.org//abs/2309.15084)`uncheck`

	Pratyusha Ria Kalluri, William Agnew, Myra Cheng, Kentrell Owens, Luca Soldaini, Abeba Birhane


+ [ Unveiling Fairness Biases in Deep Learning-Based Brain MRI  Reconstruction](https://arxiv.org//abs/2309.14392)`uncheck`

	Yuning Du, Yuyang Xue, Rohan Dharmakumar, Sotirios A. Tsaftaris


+ [ LogGPT: Log Anomaly Detection via GPT](https://arxiv.org//abs/2309.14482)`uncheck`

	Xiao Han, Shuhan Yuan, Mohamed Trabelsi


+ [ Privacy-preserving and Privacy-attacking Approaches for Speech and Audio  -- A Survey](https://arxiv.org//abs/2309.15087)`uncheck`

	Yuchen Liu, Apu Kapadia, Donald Williamson

## 2023-09-26
+ [ Investigating Efficient Deep Learning Architectures For Side-Channel  Attacks on AES](https://arxiv.org//abs/2309.13170)`uncheck`

	Yohaï-Eliel Berreby, Laurent Sauvage


+ [ Towards Green AI in Fine-tuning Large Language Models via Adaptive  Backpropagation](https://arxiv.org//abs/2309.13192)`uncheck`

	Kai Huang, Hanyun Yin, Heng Huang, Wei Gao


+ [ Defending Pre-trained Language Models as Few-shot Learners against  Backdoor Attacks](https://arxiv.org//abs/2309.13256)`uncheck`

	Zhaohan Xi, Tianyu Du, Changjiang Li, Ren Pang, Shouling Ji, Jinghui Chen, Fenglong Ma, Ting Wang


+ [ LLMs as Counterfactual Explanation Modules: Can ChatGPT Explain  Black-box Text Classifiers?](https://arxiv.org//abs/2309.13340)`uncheck`

	Amrita Bhattacharjee, Raha Moraffah, Joshua Garland, Huan Liu


+ [ Seeing Is Not Always Believing: Invisible Collision Attack and Defence  on Pre-Trained Models](https://arxiv.org//abs/2309.13579)`uncheck`

	Minghang Deng, Zhong Zhang, Junming Shao


+ [ PRIS: Practical robust invertible network for image steganography](https://arxiv.org//abs/2309.13620)`uncheck`

	Hang Yang, Yitian Xu, Xuhua Liu, Xiaodong Ma


+ [ GHN-QAT: Training Graph Hypernetworks to Predict Quantization-Robust  Parameters of Unseen Limited Precision Neural Networks](https://arxiv.org//abs/2309.13773)`uncheck`

	Stone Yun, Alexander Wong


+ [ Can LLM-Generated Misinformation Be Detected?](https://arxiv.org//abs/2309.13788)`uncheck`

	Canyu Chen, Kai Shu


+ [ RBFormer: Improve Adversarial Robustness of Transformer by Robust Bias](https://arxiv.org//abs/2309.13245)`uncheck`

	Hao Cheng, Jinhao Duan, Hui Li, Lyutianyang Zhang, Jiahang Cao, Ping Wang, Jize Zhang, Kaidi Xu, Renjing Xu


+ [ DFRD: Data-Free Robustness Distillation for Heterogeneous Federated  Learning](https://arxiv.org//abs/2309.13546)`uncheck`

	Kangyang Luo, Shuai Wang, Yexuan Fu, Xiang Li, Yunshi Lan, Ming Gao


+ [ Vulnerabilities in Video Quality Assessment Models: The Challenge of  Adversarial Attacks](https://arxiv.org//abs/2309.13609)`uncheck`

	Ao-Xiang Zhang, Yu Ran, Weixuan Tang, Yuan-Gen Wang


+ [ Video Adverse-Weather-Component Suppression Network via Weather  Messenger and Adversarial Backpropagation](https://arxiv.org//abs/2309.13700)`uncheck`

	Yijun Yang, Angelica I. Aviles-Rivero, Huazhu Fu, Ye Liu, Weiming Wang, Lei Zhu


+ [ Combining Two Adversarial Attacks Against Person Re-Identification  Systems](https://arxiv.org//abs/2309.13763)`uncheck`

	Eduardo de O. Andrade, Igor Garcia Ballhausen Sampaio, Joris Guérin, José Viterbo


+ [ Adversarial Attacks on Video Object Segmentation with Hard Region  Discovery](https://arxiv.org//abs/2309.13857)`uncheck`

	Ping Li, Yu Zhang, Li Yuan, Jian Zhao, Xianghua Xu, Xiaoqin Zhang


+ [ SurrogatePrompt: Bypassing the Safety Filter of Text-To-Image Models via  Substitution](https://arxiv.org//abs/2309.14122)`uncheck`

	Zhongjie Ba, Jieming Zhong, Jiachen Lei, Peng Cheng, Qinglong Wang, Zhan Qin, Zhibo Wang, Kui Ren



+ [ Spatial-frequency channels, shape bias, and adversarial robustness](https://arxiv.org//abs/2309.13190)`uncheck`

	Ajay Subramanian, Elena Sizikova, Najib J. Majaj, Denis G. Pelli


+ [ Beyond Fairness: Age-Harmless Parkinson's Detection via Voice](https://arxiv.org//abs/2309.13292)`uncheck`

	Yicheng Wang, Xiaotian Han, Leisheng Yu, Na Zou


+ [ Tackling the Unlimited Staleness in Federated Learning with Intertwined  Data and Device Heterogeneities](https://arxiv.org//abs/2309.13536)`uncheck`

	Haoming Wang, Wei Gao


+ [ Improving Robustness of Deep Convolutional Neural Networks via  Multiresolution Learning](https://arxiv.org//abs/2309.13752)`uncheck`

	Hongyan Zhou, Yao Liang


+ [ Invisible Watermarking for Audio Generation Diffusion Models](https://arxiv.org//abs/2309.13166)`uncheck`

	Xirong Cao, Xiang Li, Divyesh Jadav, Yanzhao Wu, Zhehui Chen, Chen Zeng, Wenqi Wei


+ [ On the Effectiveness of Adversarial Samples against Ensemble  Learning-based Windows PE Malware Detectors](https://arxiv.org//abs/2309.13841)`uncheck`

	Trong-Nghia To, Danh Le Kim, Do Thi Thu Hien, Nghi Hoang Khoa, Hien Do Hoang, Phan The Duy, Van-Hau Pham


## 2023-09-25
+ [ Provably Robust and Plausible Counterfactual Explanations for Neural  Networks via Robust Optimisation](https://arxiv.org//abs/2309.12545)`uncheck`

	Junqi Jiang, Jianglin Lan, Francesco Leofante, Antonio Rago, Francesca Toni


+ [ HANS, are you clever? Clever Hans Effect Analysis of Neural Systems](https://arxiv.org//abs/2309.12481)`uncheck`

	Leonardo Ranaldi, Fabio Massimo Zanzotto


+ [ Privacy Assessment on Reconstructed Images: Are Existing Evaluation  Metrics Faithful to Human Perception?](https://arxiv.org//abs/2309.13038)`uncheck`

	Xiaoxiao Sun, Nidham Gazagnadou, Vivek Sharma, Lingjuan Lyu, Hongdong Li, Liang Zheng


+ [ Improving Machine Learning Robustness via Adversarial Training](https://arxiv.org//abs/2309.12593)`uncheck`

	Long Dang, Thushari Hapuarachchi, Kaiqi Xiong, Jing Lin


+ [ On Data Fabrication in Collaborative Vehicular Perception: Attacks and  Countermeasures](https://arxiv.org//abs/2309.12955)`uncheck`

	Qingzhao Zhang, Shuowei Jin, Jiachen Sun, Xumiao Zhang, Ruiyang Zhu, Qi Alfred Chen, Z. Morley Mao


+ [ Understanding Deep Gradient Leakage via Inversion Influence Functions](https://arxiv.org//abs/2309.13016)`uncheck`

	Haobo Zhang, Junyuan Hong, Yuyang Deng, Mehrdad Mahdavi, Jiayu Zhou


+ [ Robotic Handling of Compliant Food Objects by Robust Learning from  Demonstration](https://arxiv.org//abs/2309.12856)`uncheck`

	Ekrem Misimi, Alexander Olofsson, Aleksander Eilertsen, Elling Ruud Øye, John Reidar Mathiassen


## 2023-09-24
+ [ Distilling Adversarial Prompts from Safety Benchmarks: Report for the  Adversarial Nibbler Challenge](https://arxiv.org//abs/2309.11575)

	Manuel Brack, Patrick Schramowski, Kristian Kersting


+ [ The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A"](https://arxiv.org//abs/2309.12288)

	Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, Owain Evans


## 2023-09-23
+ [ Bad Actor, Good Advisor: Exploring the Role of Large Language Models in  Fake News Detection](https://arxiv.org//abs/2309.12247)

	Beizhe Hu, Qiang Sheng, Juan Cao, Yuhui Shi, Yang Li, Danding Wang, Peng Qi


+ [ A Chinese Prompt Attack Dataset for LLMs with Evil Content](https://arxiv.org//abs/2309.11830)

	Chengyuan Liu, Fubang Zhao, Lizhi Qing, Yangyang Kang, Changlong Sun, Kun Kuang, Fei Wu


+ [ Vulnerability of 3D Face Recognition Systems to Morphing Attacks](https://arxiv.org//abs/2309.12118)

	Sanjeet Vardam, Luuk Spreeuwers


+ [ Towards Differential Privacy in Sequential Recommendation: A Noisy Graph  Neural Network Approach](https://arxiv.org//abs/2309.11515)

	Wentao Hu, Hui Fang


## 2023-09-22
+ [ CATS: Conditional Adversarial Trajectory Synthesis for  Privacy-Preserving Trajectory Data Publication Using Deep Learning Approaches](https://arxiv.org//abs/2309.11587)

	Jinmeng Rao, Song Gao, Sijia Zhu


+ [ How Robust is Google's Bard to Adversarial Image Attacks?](https://arxiv.org//abs/2309.11751)

	Yinpeng Dong, Huanran Chen, Jiawei Chen, Zhengwei Fang, Xiao Yang, Yichi Zhang, Yu Tian, Hang Su, Jun Zhu


+ [ Knowledge Sanitization of Large Language Models](https://arxiv.org//abs/2309.11852)

	Yoichi Ishibashi, Hidetoshi Shimodaira


+ [ On the Relationship between Skill Neurons and Robustness in Prompt  Tuning](https://arxiv.org//abs/2309.12263)

	Leon Ackermann, Xenia Ohmer


+ [ TextCLIP: Text-Guided Face Image Generation And Manipulation Without  Adversarial Training](https://arxiv.org//abs/2309.11923)

	Xiaozhou You, Jian Zhang


+ [ Dictionary Attack on IMU-based Gait Authentication](https://arxiv.org//abs/2309.11766)

	Rajesh Kumar, Can Isik, Chilukuri K. Mohan
  

+ [ Privacy-Preserving In-Context Learning with Differentially Private  Few-Shot Generation](https://arxiv.org//abs/2309.11765)

	Xinyu Tang, Richard Shin, Huseyin A. Inan, Andre Manoel, Fatemehsadat Mireshghallah, Zinan Lin, Sivakanth Gopi, Janardhan Kulkarni, Robert Sim


+ [ MarkNerf:Watermarking for Neural Radiance Field](https://arxiv.org//abs/2309.11747)

	Lifeng Chen, Jia Liu, Yan Ke, Wenquan Sun, Weina Dong, Xiaozhong Pan


+ [ DeepTheft: Stealing DNN Model Architectures through Power Side Channel](https://arxiv.org//abs/2309.11894)

	Yansong Gao, Huming Qiu, Zhi Zhang, Binghui Wang, Hua Ma, Alsharif Abuadbba, Minhui Xue, Anmin Fu, Surya Nepal


## 2023-09-21
+ [ When to Trust AI: Advances and Challenges for Certification of Neural  Networks](https://arxiv.org//abs/2309.11196)

	Marta Kwiatkowska, Xiyue Zhang


+ [ C$\cdot$ASE: Learning Conditional Adversarial Skill Embeddings for  Physics-based Characters](https://arxiv.org//abs/2309.11351)

	Zhiyang Dou, Xuelin Chen, Qingnan Fan, Taku Komura, Wenping Wang


+ [ What Learned Representations and Influence Functions Can Tell Us About  Adversarial Examples](https://arxiv.org//abs/2309.10916)

	Shakila Mahjabin Tonni, Mark Dras


+ [ PRAT: PRofiling Adversarial aTtacks](https://arxiv.org//abs/2309.11111)

	Rahul Ambati, Naveed Akhtar, Ajmal Mian, Yogesh Singh Rawat


+ [ It's Simplex! Disaggregating Measures to Improve Certified Robustness](https://arxiv.org//abs/2309.11005)

	Andrew C. Cullen, Paul Montague, Shijie Liu, Sarah M. Erfani, Benjamin I.P. Rubinstein


+ [ Learning Patient Static Information from Time-series EHR and an Approach  for Safeguarding Privacy and Fairness](https://arxiv.org//abs/2309.11373)

	Wei Liao, Joel Voldman


+ [ Fed-LSAE: Thwarting Poisoning Attacks against Federated Cyber Threat  Detection System via Autoencoder-based Latent Space Inspection](https://arxiv.org//abs/2309.11053)

	Tran Duc Luong, Vuong Minh Tien, Nguyen Huu Quyen, Do Thi Thu Hien, Phan The Duy, Van-Hau Pham


## 2023-09-20
+ [ GPTFUZZER : Red Teaming Large Language Models with Auto-Generated  Jailbreak Prompts](https://arxiv.org//abs/2309.10253) 

  Jiahao Yu, Xingwei Lin, Xinyu Xing


+ [ Exploring the Dark Side of AI: Advanced Phishing Attack Design and  Deployment Using ChatGPT](https://arxiv.org//abs/2309.10463) 

  Nils Begou, Jeremy Vinoy, Andrzej Duda, Maciej Korczynski


+ [ Transferable Adversarial Attack on Image Tampering Localization](https://arxiv.org//abs/2309.10243)

  Yuqi Wang, Gang Cao, Zijie Lou, Haochen Zhu


+ [ RECALL+: Adversarial Web-based Replay for Continual Learning in Semantic  Segmentation](https://arxiv.org//abs/2309.10479)

  Chang Liu, Giulia Rizzoli, Francesco Barbato, Umberto Michieli, Yi Niu, Pietro Zanuttigh


+ [ Realistic Website Fingerprinting By Augmenting Network Trace](https://arxiv.org//abs/2309.10147)

  Alireza Bahramali, Ardavan Bozorgi, Amir Houmansadr


+ [ Love or Hate? Share or Split? Privacy-Preserving Training Using Split  Learning and Homomorphic Encryption](https://arxiv.org//abs/2309.10517) 

  Tanveer Khan, Khoa Nguyen, Antonis Michalas, Alexandros Bakas


+ [ Disentangled Information Bottleneck guided Privacy-Protective JSCC for  Image Transmission](https://arxiv.org//abs/2309.10263)

  Lunan Sun, Yang Yang, Mingzhe Chen, Caili Guo


+ [ SPFL: A Self-purified Federated Learning Method Against Poisoning  Attacks](https://arxiv.org//abs/2309.10607) 

  Zizhen Liu, Weiyang He, Chip-Hong Chang, Jing Ye, Huawei Li, Xiaowei Li


## 2023-09-19
+ [ Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents](https://arxiv.org//abs/2309.09919)

  Ziyi Yang, Shreyas S. Raman, Ankit Shah, Stefanie Tellex


+ [ Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract  Code Using Vulnerability-constrained Decoding](https://arxiv.org//abs/2309.09826)

  André Storhaug, Jingyue Li, Tianyuan Hu


+ [ Bias of AI-Generated Content: An Examination of News Produced by Large  Language Models](https://arxiv.org//abs/2309.09825)

  Xiao Fang, Shangkun Che, Minjia Mao, Hongzhe Zhang, Ming Zhao, Xiaohang Zhao


+ [ Reducing Adversarial Training Cost with Gradient Approximation](https://arxiv.org//abs/2309.09464)

  Huihui Gong, Shuo Yang, Siqi Ma, Seyit Camtepe, Surya Nepal, Chang Xu


+ [ Stealthy Physical Masked Face Recognition Attack via Adversarial Style  Optimization](https://arxiv.org//abs/2309.09480)

  Huihui Gong, Minjing Dong, Siqi Ma, Seyit Camtepe, Surya Nepal, Chang Xu


+ [ Evaluating Adversarial Robustness with Expected Viable Performance](https://arxiv.org//abs/2309.09928)

  Ryan McCoppin, Colin Dawson, Sean M. Kennedy, Leslie M. Blaha

## 2023-09-17

+ [ Convex Latent-Optimized Adversarial Regularizers for Imaging Inverse  Problems](https://arxiv.org//abs/2309.09250)

  Huayu Wang, Chen Luo, Taofeng Xie, Qiyu Jin, Guoqing Chen, Zhuo-Xu Cui, Dong Liang

## 2023-09-16


+ [ Robust Backdoor Attacks on Object Detection in Real World](https://arxiv.org//abs/2309.08953)

  Yaguan Qian, Boyuan Ji, Shuke He, Shenhui Huang, Xiang Ling, Bin Wang, Wei Wang


+ [ Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and  Nationality Bias in Generative Models](https://arxiv.org//abs/2309.08902)

  Mahammed Kamruzzaman, Md. Minul Islam Shovon, Gene Louis Kim
 

+ [ Context-aware Adversarial Attack on Named Entity Recognition](https://arxiv.org//abs/2309.08999)

  Shuguang Chen, Leonardo Neves, Thamar Solorio
 
## 2023-09-15

+ [ Adversarial Attacks on Tables with Entity Swap](https://arxiv.org//abs/2309.08650)

  Aneta Koleva, Martin Ringsquandl, Volker Tresp


+ [ A More Secure Split: Enhancing the Security of Privacy-Preserving Split  Learning](https://arxiv.org//abs/2309.08697)

  Tanveer Khan, Khoa Nguyen, Antonis Michalas

  
+ [ Detecting Unknown Attacks in IoT Environments: An Open Set Classifier  for Enhanced Network Intrusion Detection](https://arxiv.org//abs/2309.07461)

  Yasir Ali Farrukh, Syed Wali, Irfan Khan, Nathaniel D. Bastian


+ [ Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated  Text](https://arxiv.org//abs/2309.07689)

  Mahdi Dhaini, Wessel Poelman, Ege Erdogan


+ [ Keep your Identity Small: Privacy-preserving Client-side Fingerprinting](https://arxiv.org//abs/2309.07563)

  Alberto Fernandez-de-Retana, Igor Santos-Grueiro


+ [ Fake News Detectors are Biased against Texts Generated by Large Language  Models](https://arxiv.org//abs/2309.08674)

  Jinyan Su, Terry Yue Zhuo, Jonibek Mansurov, Di Wang, Preslav Nakov
